{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f0b75-e0fb-4705-8c3d-32029a57a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import sys,os,shutil,gc,re,json,glob,math,time,random,warnings\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ffd02-069b-4518-8a4b-e7e1ade2aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PROCESSED_DATA = os.environ['DIR_PROCESSED_DATA']\n",
    "# DIR_PROCESSED_DATA = '/home/jovyan/digilut/data/processed'\n",
    "DIR_TILES = f'{DIR_PROCESSED_DATA}/workspace/train/tiles'\n",
    "DIR_TRAIN_CROPS = f'{DIR_PROCESSED_DATA}/p3_crops_p_100_500'\n",
    "DIR_TRAIN_DATASET_OUT =  f'{DIR_PROCESSED_DATA}/p3'\n",
    "os.makedirs(DIR_TRAIN_DATASET_OUT,exist_ok=True)\n",
    "\n",
    "MIN_QUALITY_SCORE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c8f35-91ce-4572-b809-694d2a83d425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb42215-bd74-4b19-9f84-0f0f32662297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f'{DIR_TRAIN_CROPS}/anno.pkl').rename(columns={'fileid':'file_id','slideid':'slide_id'})\n",
    "df['path'] = DIR_TRAIN_CROPS + '/' + df.file_id\n",
    "df['category_id'] = 0\n",
    "df['bbid'] = df.og_bbox.astype(str)\n",
    "df.describe(percentiles=[i/10 for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0854c8-0a28-43c3-bbfb-53de6adb29b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbf1f6-ae14-4b0a-8b3e-f32d5a5836e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_boxes_intersect(x1, y1, x2, y2, X1, Y1, X2, Y2):\n",
    "    if x1 < X2 and x2 > X1 and y1 < Y2 and y2 > Y1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def load_neg(base_sz):\n",
    "    paths = glob.glob(f'{DIR_TILES}/{base_sz}/*/*/img/*')\n",
    "    df_neg = pd.DataFrame(dict(path=paths))\n",
    "    df_neg['slide_id'] = df_neg.path.str.split('/').str[-3]\n",
    "    df_neg['sz'] = df_neg.path.str.split('/').str[-4]\n",
    "    df_neg['file_id'] = df_neg.slide_id+'_'+df_neg.sz+'_'+df_neg.path.str.split('/').str[-1]\n",
    "    df_neg['tile_id'] = df_neg.path.str.split('/').str[-1].str.split('_').str[0].astype(np.int32)\n",
    "    d1 = df_neg.file_id.str.split('.').str[0].str.rsplit('_',n=3,expand=True).drop(columns=1)\n",
    "    d1.columns = ['slide_id','y','x']\n",
    "    # df_res['slide_id'] = d1.slide_id\n",
    "    df_neg['x1'] = d1.x.astype(int)\n",
    "    df_neg['y1'] = d1.y.astype(int)\n",
    "\n",
    "    paths=glob.glob(f'{DIR_TILES}/{base_sz}/*/*/*.csv')\n",
    "    lens=[]\n",
    "    d_tiles = []\n",
    "    notiles=[]\n",
    "    for p in paths:\n",
    "        try:\n",
    "            d=pd.read_csv(p)\n",
    "            lens.append(len(d))\n",
    "            d_tiles.append(d)\n",
    "        except:\n",
    "            notiles.append(p)\n",
    "\n",
    "    d_tiles=pd.concat(d_tiles).sort_values(by=['slide_id','tile_id']).reset_index(drop=True)\n",
    "    d_tiles = d_tiles.rename(columns={'w':'twidth','h':'theight'})\n",
    "    df_neg = pd.merge(df_neg,d_tiles,on=['slide_id','tile_id'])\n",
    "    df_neg['base_sz'] = base_sz\n",
    "    df_neg = df_neg[df_neg.Score>=MIN_QUALITY_SCORE]\n",
    "\n",
    "    intersects = []\n",
    "    for _,row in tqdm(df_neg.iterrows(),total=len(df_neg)):\n",
    "        inter = False\n",
    "        tile_bounds = [row.x1,row.y1,row.x1+row.twidth,row.y1+row.theight]\n",
    "        X1,Y1,X2,Y2 = tile_bounds\n",
    "        slide_bbs = df[df.slide_id==row.slide_id].full_bbox.tolist()\n",
    "        for bb in slide_bbs:\n",
    "            x1,y1,x2,y2 = bb\n",
    "            inter = do_boxes_intersect(x1, y1, x2, y2, X1, Y1, X2, Y2)\n",
    "            if inter:\n",
    "                break #no need to continue checking\n",
    "\n",
    "        intersects.append(inter)\n",
    "    # d_tiles = d_tiles[['slide_id','tile_id','twidth','theight','swidth','sheight']]\n",
    "    # d_tiles['x1'] =\n",
    "\n",
    "    df_neg['has_bb'] = intersects\n",
    "    display(df_neg.has_bb.value_counts())\n",
    "    df_neg = df_neg[~df_neg.has_bb].reset_index(drop=True)\n",
    "    return df_neg\n",
    "dfs = []\n",
    "# for base_sz in [128]:\n",
    "for base_sz in [128,160,192,224,256]:\n",
    "    df_neg = load_neg(base_sz)\n",
    "    dfs.append(df_neg)\n",
    "\n",
    "df_neg = pd.concat(dfs).reset_index(drop=True)\n",
    "df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee0dae-9d40-4914-83bc-67c6e14ce455",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.concat([df,df_neg]).reset_index(drop=True)\n",
    "meta = meta.drop_duplicates(subset=['file_id'])\n",
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca3a9bd9-761f-4be3-9520-2c7182ecbc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2678/2678 [00:00<00:00, 4857.77it/s]\n"
     ]
    }
   ],
   "source": [
    "out_dir = f'{DIR_TRAIN_DATASET_OUT}/images'\n",
    "os.makedirs(out_dir,exist_ok=True)\n",
    "for file_name,d in tqdm(meta.groupby('file_id')):\n",
    "    path = d.path.values[0]\n",
    "    # im = cv2.imread(path)\n",
    "    # height,width,_ = im.shape\n",
    "    shutil.copy2(path, f'{out_dir}/{file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "827ad135-746d-4bba-ae18-ec7a828958c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg.to_pickle(f'{DIR_TRAIN_DATASET_OUT}/neg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "070339f4-f386-4da8-abc4-0edfaa26e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f'{DIR_TRAIN_DATASET_OUT}/anno.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
